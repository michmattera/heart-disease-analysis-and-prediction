{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Feature engineering Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Engineer features for Classification\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/TrainSetCleaned.csv\n",
    "* outputs/datasets/cleaned/TestSetCleaned.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate a list with variebles to use in model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
    "TrainSet = pd.read_csv(train_set_path)\n",
    "TrainSet.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = \"outputs/datasets/cleaned/TestSetCleaned.csv\"\n",
    "TestSet = pd.read_csv(test_set_path)\n",
    "TestSet.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been check and cleaned , ready for feature engineering step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Custom function for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Feature engineering is a crucial step in the data preprocessing process, and it can significantly impact the performance of the machine learning models\n",
    "We are going to use the custom function from the Code Institute walkthrough project 'Churnometer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape\n",
    "    - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    # Loop in each variable and engineer the data according to the analysis type\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "        # create additional columns (column_method) to apply the methods\n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        # Apply transformers in respective column_transformers\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
    "            analysis_type, df_feat_eng, column)\n",
    "\n",
    "        # For each variable, assess how the transformations perform\n",
    "        transformer_evaluation(\n",
    "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    \"\"\" Check analysis type \"\"\"\n",
    "    if analysis_type is None:\n",
    "        raise SystemExit(\n",
    "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(\n",
    "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\n",
    "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    # For each variable, assess how the transformations perform\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "    for col in [column] + list_applied_transformers:\n",
    "\n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
    "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    axes[0].set_title('Histogram')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
    "                                 f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # Winsorizer iqr\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # LogTransformer base e\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    # LogTransformer base 10\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    # ReciprocalTransformer\n",
    "    try:\n",
    "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    # PowerTransformer\n",
    "    try:\n",
    "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
    "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    # BoxCoxTransformer\n",
    "    try:\n",
    "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    # YeoJohnsonTransformer\n",
    "    try:\n",
    "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering = [\n",
    "    'age',\n",
    "    'sex',\n",
    "    'cp',\n",
    "    'trestbps',\n",
    "    'chol',\n",
    "    'fbs',\n",
    "    'restecg',\n",
    "    'thalach',\n",
    "    'exang',\n",
    "    'oldpeak',\n",
    "    'slope',\n",
    "    'ca',\n",
    "    'thal'\n",
    "    ]\n",
    "\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing shapiro test to assess normality of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Perform the Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(df_engineering)\n",
    "\n",
    "# Check the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The data significantly deviates from a normal distribution.\")\n",
    "else:\n",
    "    print(\"The data does not significantly deviate from a normal distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "before_transformation_results = pd.DataFrame(columns=[\"Variable\", \"Shapiro-Wilk p-value (Before)\"])\n",
    "\n",
    "for column in df_engineering.columns:\n",
    "    # Extract the data for the current column\n",
    "    data = df_engineering[column].values\n",
    "\n",
    "    # Before Transformation:\n",
    "    # Perform the Shapiro-Wilk test for normality\n",
    "    statistic_before, p_value_before = stats.shapiro(data)\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    before_transformation_results = before_transformation_results.append({\n",
    "        \"Variable\": column,\n",
    "        \"Shapiro-Wilk p-value (Before)\": p_value_before\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Print the results for the original data (before transformation)\n",
    "print(\"Results Before Transformation:\")\n",
    "print(before_transformation_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Variable Transformations\r\n",
    "\r\n",
    "Here's a breakdown of the variables and potential transformation methods based on ted data:\r\n",
    "\r\n",
    "1. **age**: Consider applying a logarithmic transformation (log_e, log_10), reciprocal transformation, or Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "2. **sex**: This binary variable may not benefit from transformations. It's typically left as-is for a classification task.\r\n",
    "\r\n",
    "3. **cp (chest pain type)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "4. **trestbps (resting blood pressure)**: Consider a logarithmic transformation (log_e, log_10), reciprocal transformation, or Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "5. **chol (serum cholesterol)**: Consider a logarithmic transformation (log_e, log_10), reciprocal transformation, or Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "6. **fbs (fasting blood sugar)**: This binary variable may not benefit from transformations. It's typically left as-is for classification tasks.\r\n",
    "\r\n",
    "7. **restecg (resting electrocardiographic results)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "8. **thalach (maximum heart rate achieved)**: Consider a logarithmic transformation (log_e, log_10), reciprocal transformation, or Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "9. **exang (exercise-induced angina)**: This binary variable may not benefit from transformations. It's typically left as-is for classification tasks.\r\n",
    "\r\n",
    "10. **oldpeak (ST depression induced by exercise)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "11. **slope (slope of the peak exercise ST segment)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "12. **ca (number of major vessels colored by fluoroscopy)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "\r\n",
    "13. **thal (thalassemia)**: Depending on the nature of the data, consider a Box-Cox/Yeo-Johnson transformation with an estimated lambda.\r\n",
    "th an estimated lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the statistical and visual investigation , developer choose to consider **Box-Cox/Yeo-Johnson** as the transformation method, since most of the variables could benefit from it. Because box-cox give error for not positive numbers, developer chose to use **Yeo Johnson**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeo Johnson Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine import transformation as vt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Variables that may benefit from Yeo-Johnson transformation\n",
    "variables_to_transform = [\n",
    "    'age',\n",
    "    'cp',\n",
    "    'trestbps',\n",
    "    'chol',\n",
    "    'restecg',\n",
    "    'thalach',\n",
    "    'oldpeak',\n",
    "    'slope',\n",
    "    'ca',\n",
    "    'thal'\n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply Yeo-Johnson only to selected variables\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[('yeo_johnson', vt.YeoJohnsonTransformer(), variables_to_transform)],\n",
    "    remainder='passthrough'  # Include other columns as is\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('yeo_johnson_transform', column_transformer)\n",
    "])\n",
    "\n",
    "# Apply the Yeo-Johnson transformation to the selected variables\n",
    "df_transformed = pipeline.fit_transform(df_engineering)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=df_engineering.columns)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_engine import transformation as vt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables that may benefit from Yeo-Johnson transformation\n",
    "variables_to_transform = [\n",
    "    'age',\n",
    "    'cp',\n",
    "    'trestbps',\n",
    "    'chol',\n",
    "    'restecg',\n",
    "    'thalach',\n",
    "    'oldpeak',\n",
    "    'slope',\n",
    "    'ca',\n",
    "    'thal'\n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply Yeo-Johnson only to selected variables\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[('yeo_johnson', vt.YeoJohnsonTransformer(), variables_to_transform)],\n",
    "    remainder='passthrough'  # Include other columns as is\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('yeo_johnson_transform', column_transformer)\n",
    "])\n",
    "\n",
    "# Apply the Yeo-Johnson transformation to the selected variables\n",
    "df_transformed = pipeline.fit_transform(df_engineering)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=df_engineering.columns)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(df_transformed.head())\n",
    "\n",
    "for variable in variables_to_transform:\n",
    "    original_data = df_engineering[variable]\n",
    "    transformed_data = df_transformed[variable]\n",
    "\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(original_data, bins=20, color='blue', alpha=0.7, label='Original')\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.title(f'Histogram for Original {variable}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(transformed_data, bins=20, color='green', alpha=0.7, label='Transformed')\n",
    "    plt.xlabel(f'Transformed {variable}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.title(f'Histogram for Transformed {variable}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Q-Q plots\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    stats.probplot(original_data, dist='norm', plot=plt)\n",
    "    plt.title(f'Q-Q Plot for Original {variable}')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(transformed_data, dist='norm', plot=plt)\n",
    "    plt.title(f'Q-Q Plot for Transformed {variable}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the graphical and statistical observations above that transformations improved the distribution of data, but not necessarly his normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer will keep the transformations and decide based on the model performance next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartCorrelatedSelection Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet.copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
    "\n",
    "corr_sel.fit_transform(df_engineering)\n",
    "corr_sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on smartcorrelated feature there are no features to drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The list below shows the transformations needed for feature engineering. These steps will be added to the ML Pipeline\n",
    "Both BoxCox and YeoJohnson transformer were observed, but boxcox gave an error when trying to fit model, in ModelAndEvaluation notebook, saying that data must be positive. Developer choose YeoJohnson because the two transformation perform relatively close and it was not given any error.\r\n",
    "\r\n",
    "**Feature Engineering Transformer**\r\n",
    "- **Yeo-Johnson numerical transformer**: Applies Yeo-Johnson transformation to the following numerical features: 'age', 'cp', 'trestbps', 'chol', 'restecg', 'thalach', 'oldpeak', 'slope', 'ca', 'thal'.\r\n",
    "\r\n",
    "**Smart Correlation Detection**\r\n",
    "- None found.\r\n",
    "corical enc**Categooding**\n",
    "- Not .red.\r\n",
    "t']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
