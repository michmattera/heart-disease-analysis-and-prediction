{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Data Cleaning Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Clean the data\n",
    "- Spli data for train and test set\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/heart.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate Train and Test sets from cleaned data, saved under outputs/datasets/cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_raw_path = \"outputs/datasets/collection/heart.csv\"\n",
    "df = pd.read_csv(df_raw_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Check inbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed in the previous notebook that some of the variables were unbalanced.\n",
    "Developer will visualize all features with countplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for feature in df.columns:\n",
    "    if feature != 'target':  # Exclude the target variable itself\n",
    "        plt.figure(figsize=(8, 4))  # Adjust figure size as needed\n",
    "        sns.countplot(x=feature, hue='target', data=df, palette='Set2')\n",
    "        plt.title(f'Class Distribution by {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(title='Target', loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualize all features and because of the nature of the business problem **Classification**, the needs balanced features developer decided to handle feature inbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking all variable count to confirm unbalanced variables from countplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for column in df.columns:\n",
    "    counts = df[column].value_counts()\n",
    "    print(f\"Value Counts for {column}:\\n{counts}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above Developer decided that the unbalanced variables are the following\n",
    "\n",
    "- sex\n",
    "- FBS (Fasting Blood Sugar)\r",
    "- \n",
    "Restecg (Resting Electrocardiographic Results)- \r\n",
    "Exang (Exercise-Induced Angina- )\r\n",
    "Slo- pe\r\n",
    "\n",
    "\n",
    "As well developer decided to split data, feature engineering, evaluate performance of the model and if needed balance the variables described above.Thal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the target variable as the developer think that this split of the data is the one that leaked to target leakage and to the bug of 100% accuracy in train and test set, in the model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = df.drop('target', axis=1)  # drop the target variable from the feature set\n",
    "target = df['target']\n",
    "\n",
    "TrainSet, TestSet, train_target, test_target = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice the train and test set are divide as follow\n",
    "\n",
    "- TrainSet shape: (820, 14) \r",
    "- \n",
    "TestSet shape: (205, 14\n",
    "\n",
    "With the train set with 80% of the data and test set with the remaining 20 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then export and save the cleaned datas in their folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned')\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)\n",
    "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and pushing file to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this notebook we understood:\n",
    "* Data did not need any cleaning\n",
    "* No missing data\n",
    "* There were few variables unbalanced\n",
    "* Developer choose to see performance of model to decide how and if balance the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
