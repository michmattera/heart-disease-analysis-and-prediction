{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Data Cleaning Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Clean the data\n",
    "- Spli data for train and test set\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/heart.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate Train and Test sets from cleaned data, saved under outputs/datasets/cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_raw_path = \"outputs/datasets/collection/heart.csv\"\n",
    "df = pd.read_csv(df_raw_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Check inbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed in the previous notebook that some of the variables were unbalanced.\n",
    "Developer will visualize all features with countplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for feature in df.columns:\n",
    "    if feature != 'target':  # Exclude the target variable itself\n",
    "        plt.figure(figsize=(8, 4))  # Adjust figure size as needed\n",
    "        sns.countplot(x=feature, hue='target', data=df, palette='Set2')\n",
    "        plt.title(f'Class Distribution by {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(title='Target', loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking all variable count to confirm unbalanced variables from countplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for column in df.columns:\n",
    "    counts = df[column].value_counts()\n",
    "    print(f\"Value Counts for {column}:\\n{counts}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above Developer decided that the unbalanced variables are the following:\n",
    "\n",
    "* sex\n",
    "* FBS (Fasting Blood Sugar)\r",
    "* Restecg (Resting Electrocardiographic Results)\n",
    "* Exang (Exercise-Induced Angine )\n",
    "* Slope- *- Thap\r\n",
    "\n",
    "\n",
    "As well developer decided to split data, feature engineering, evaluate performance of the model and if needed balance the variables described ave.al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the target variable as the developer think that this split of the data is the one that leaked to target leakage and to the bug of 100% accuracy in train and test set, in the model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['target'], axis=1),\n",
    "    df['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice the train and test set are divide as follow: \n",
    "* TrainSet shape: (820, 13)\n",
    "* TestSet shape: (205, )\n",
    "\n",
    "With the train set with 80% of the data and test set with the remaining 20 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section was added in a second moment , when developer understood that In ModelAndEvaluation notebook, duplicates were bringing performance of train and test set to 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Combine train and test data into one DataFrame\n",
    "X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "y_combined = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = X_combined.duplicated()\n",
    "duplicates_exist = duplicates.any()\n",
    "\n",
    "if duplicates_exist:\n",
    "    print(\"Duplicates exist between train and test sets.\")\n",
    "else:\n",
    "    print(\"No duplicates found between train and test sets.\")\n",
    "\n",
    "# Print the shapes of train and test sets\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of duplicates in the train set\n",
    "train_duplicates = X_train[X_train.duplicated(keep='first')]\n",
    "num_train_duplicates = len(train_duplicates)\n",
    "\n",
    "# Check the number of duplicates in the test set\n",
    "test_duplicates = X_test[X_test.duplicated(keep='first')]\n",
    "num_test_duplicates = len(test_duplicates)\n",
    "\n",
    "print(\"Number of duplicates in the train set:\", num_train_duplicates)\n",
    "print(\"Number of duplicates in the test set:\", num_test_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are duplicates in train and test set:\n",
    "\n",
    "- Number of duplicates in the train set: 519\n",
    "- Number of duplicates in the test set: 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing duplicates from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the test set\n",
    "X_test = X_test.drop_duplicates(keep='first')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Check the shape of the test set after removing duplicates\n",
    "print(\"Test set shape after removing duplicates:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the train set\n",
    "X_train = X_train.drop_duplicates(keep='first')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# Check the shape of the train set after removing duplicates\n",
    "print(\"Train set shape after removing duplicates:\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then export and save the cleaned datas in their folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned')\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet = X_train\n",
    "TrainSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet = X_test\n",
    "TestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)\n",
    "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetTrainSet = y_train\n",
    "TargetTrainSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetTestSet = y_test\n",
    "TargetTestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetTrainSet.to_csv(\"outputs/datasets/cleaned/TargetTrainSet.csv\", index=False)\n",
    "TargetTestSet.to_csv(\"outputs/datasets/cleaned/TargetTestSet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and pushing file to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this notebook we understood:\n",
    "* Data did not need any cleaning\n",
    "* No missing data\n",
    "* There were few variables unbalanced\n",
    "* There were duplicates in train and test set, eliminated.\n",
    "* Developer choose to see performance of model to decide how and if balance the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
