{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Model and evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Fit and evaluate a classification model to predict if a patient will suffer from heart disease or not.\n",
    "- Fulfil business requirement 2.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/heart.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering , and modeling pipeline\n",
    "* Heatmap for confusion matrix report plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/heart-disease-analysis-and-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "\n",
       "   ca  thal  \n",
       "0   2     3  \n",
       "1   0     3  \n",
       "2   0     3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/heart.csv\"))\n",
    "\n",
    "# Separate predictors and target\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(X.shape)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data int train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train set: (820, 13) (820,) \n",
      "* Test set: (205, 13) (205,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['target'], axis=1),\n",
    "    df['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape after removing duplicates: (161, 13) (161,)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the test set\n",
    "X_test = X_test.drop_duplicates(keep='first')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Check the shape of the test set after removing duplicates\n",
    "print(\"Test set shape after removing duplicates:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape after removing duplicates: (301, 13) (301,)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the train set\n",
    "X_train = X_train.drop_duplicates(keep='first')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# Check the shape of the train set after removing duplicates\n",
    "print(\"Train set shape after removing duplicates:\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best combination of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the two combination of features study and found in previous notebooks:\n",
    "\n",
    "- best_features = From ModelAndEvaluation notebook, found with feature importance.\n",
    "- best_correlation_features = From FeatureSelection notebook, found with correlational study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'cp', 'thal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = ['ca', 'cp', 'thal']\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'cp', 'exang', 'oldpeak', 'thalach', 'chol']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_correlation_features = ['ca', 'cp', 'exang', 'oldpeak', 'thalach', 'chol']\n",
    "best_correlation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original best features based on correlation were ca, cp, exang, oldpeak, thalach, chol. After additional analysis, the best features are ca, cp, thal. The change made was replacing 'thalach' with 'thal'.\n"
     ]
    }
   ],
   "source": [
    "# Identify the difference between the two lists\n",
    "difference = list(set(best_correlation_features) - set(best_features))\n",
    "if difference:\n",
    "    explanation = f\"The original best features based on correlation were {', '.join(best_correlation_features)}.\"\n",
    "    explanation += f\" After additional analysis, the best features are {', '.join(best_features)}.\"\n",
    "    explanation += f\" The change made was replacing 'thalach' with 'thal'.\"\n",
    "else:\n",
    "    explanation = \"The best features based on correlation match the updated best features.\"\n",
    "\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = ['ca', 'cp', 'exang', 'oldpeak', 'thal', 'chol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 6) (301,) (161, 6) (161,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ca</th>\n",
       "      <th>cp</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>thal</th>\n",
       "      <th>chol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ca  cp  exang  oldpeak  thal  chol\n",
       "315   2   3      0      0.8     2   244\n",
       "204   1   2      0      0.0     2   278\n",
       "363   3   2      0      0.0     2   246"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filtered = X_train.filter(features_selected)\n",
    "X_test_filtered = X_test.filter(features_selected)\n",
    "\n",
    "print(X_train_filtered.shape, y_train.shape, X_test_filtered.shape, y_test.shape)\n",
    "X_train_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaxamine performance of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pipeline from \" ModelAndEvaluation notebook \" section \"We create a new pipeline, using the best model and the best hyperparameters from the research above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the following pipeline has the best model and the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def xgbclassifier_pipeline():\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['ca', 'cp', 'exang', 'oldpeak', 'thal', 'chol'])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(estimator=model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "# Create the XGBoost pipeline with hyperparameters\n",
    "xgb_pipeline = xgbclassifier_pipeline()\n",
    "xgb_pipeline.fit(X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train_selected, y_train, X_test_filtered, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train_filtered, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test_filtered, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Final Classification Report')\n",
    "\n",
    "version = 'v3'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "# Define the filename for this plot\n",
    "plot_filename_classification_report_1 = f'{file_path}/classification_report_3.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of features that finally meet the business requirements metrics with a performance of:\n",
    "\n",
    "- **Accuracy of 0.85**\n",
    "- **Precision on class 0 of 0.90**\n",
    "- Precision on class 1 of 0.82\n",
    "- **Recall of class 1 of 0.93**\n",
    "- Recall of class 0 of 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer chose this as the best combination of features ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and push file to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the following files:\n",
    "\n",
    "- Train set\n",
    "- Test set\n",
    "- Data cleaning and Feature Engineering , and modeling pipeline\n",
    "- Heatmap plot for confusion matrix report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "version = 'v3'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_filtered\n",
    "X_test = X_test_filtered\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier_pipeline = xgb_pipeline\n",
    "xgbclassifier_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(value=xgbclassifier_pipeline,\n",
    "            filename=f\"{file_path}/xgbclassifier_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save heatmap report on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 1')\n",
    "\n",
    "# Save the plot to the specified filename\n",
    "plt.savefig(plot_filename_classification_report_1, bbox_inches='tight')\n",
    "\n",
    "# Display the saved plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
