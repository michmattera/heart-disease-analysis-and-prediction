{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Model and evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Fit and evaluate a classification model to predict if a patient will suffer from heart disease or not.\n",
    "- Fulfil business requirement 2.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/heart.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering , and modeling pipeline\n",
    "* Heatmap for confusion matrix report plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/heart.csv\"))\n",
    "\n",
    "# Separate predictors and target\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(X.shape)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data int train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['target'], axis=1),\n",
    "    df['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the test set\n",
    "X_test = X_test.drop_duplicates(keep='first')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Check the shape of the test set after removing duplicates\n",
    "print(\"Test set shape after removing duplicates:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the train set\n",
    "X_train = X_train.drop_duplicates(keep='first')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# Check the shape of the train set after removing duplicates\n",
    "print(\"Train set shape after removing duplicates:\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best combination of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the two combination of features study and found in previous notebooks:\n",
    "\n",
    "- best_features = From ModelAndEvaluation notebook, found with feature importance.\n",
    "- best_correlation_features = From FeatureSelection notebook, found with correlational study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['ca', 'cp', 'thal']\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correlation_features = ['ca', 'cp', 'exang', 'oldpeak', 'thalach', 'chol']\n",
    "best_correlation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the difference between the two lists\n",
    "difference = list(set(best_correlation_features) - set(best_features))\n",
    "if difference:\n",
    "    explanation = f\"The original best features based on correlation were {', '.join(best_correlation_features)}.\"\n",
    "    explanation += f\" After additional analysis, the best features are {', '.join(best_features)}.\"\n",
    "    explanation += f\" The change made was replacing 'thalach' with 'thal'.\"\n",
    "else:\n",
    "    explanation = \"The best features based on correlation match the updated best features.\"\n",
    "\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = ['ca', 'cp', 'exang', 'oldpeak', 'thal', 'chol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train.filter(features_selected)\n",
    "X_test_filtered = X_test.filter(features_selected)\n",
    "\n",
    "print(X_train_filtered.shape, y_train.shape, X_test_filtered.shape, y_test.shape)\n",
    "X_train_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaxamine performance of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pipeline from \" ModelAndEvaluation notebook \" section \"We create a new pipeline, using the best model and the best hyperparameters from the research above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the following pipeline has the best model and the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def xgbclassifier_pipeline():\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['ca', 'cp', 'exang', 'oldpeak', 'thal', 'chol'])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(estimator=model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "# Create the XGBoost pipeline with hyperparameters\n",
    "xgb_pipeline = xgbclassifier_pipeline()\n",
    "xgb_pipeline.fit(X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train_selected, y_train, X_test_filtered, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train_filtered, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test_filtered, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Final Classification Report')\n",
    "\n",
    "version = 'v3'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "# Define the filename for this plot\n",
    "plot_filename_classification_report_1 = f'{file_path}/classification_report_3.png'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of features that finally meet the business requirements metrics with a performance of:\n",
    "\n",
    "- **Accuracy of 0.85**\n",
    "- **Precision on class 0 of 0.90**\n",
    "- Precision on class 1 of 0.82\n",
    "- **Recall of class 1 of 0.93**\n",
    "- Recall of class 0 of 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer chose this as the best combination of features ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and push file to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the following files:\n",
    "\n",
    "- Train set\n",
    "- Test set\n",
    "- Data cleaning and Feature Engineering , and modeling pipeline\n",
    "- Heatmap plot for confusion matrix report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "version = 'v3'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_filtered\n",
    "X_test = X_test_filtered\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier_pipeline = xgb_pipeline\n",
    "xgbclassifier_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(value=xgbclassifier_pipeline,\n",
    "            filename=f\"{file_path}/xgbclassifier_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save heatmap report on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 1')\n",
    "\n",
    "# Save the plot to the specified filename\n",
    "plt.savefig(plot_filename_classification_report_1, bbox_inches='tight')\n",
    "\n",
    "# Display the saved plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
