{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Model and evaluation Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Fit and evaluate a classification model to predict if a patient will suffer from heart disease or not.\n",
    "- Fulfil business requirement 2.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/TargetTestSet.csv\n",
    "* outputs/datasets/cleaned/TargetTrainSet.csv\n",
    "* outputs/datasets/cleaned/TestSetCleaned.csv\n",
    "* outputs/datasets/cleaned/TrainSetCleaned.csv\n",
    "* outputs/datasets/collection/heart.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Data cleaning and Feature Engineering and modeling pipeline\n",
    "* Feature importance plot\n",
    "* Heatmap report plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Set up the Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "Define and confirm the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/heart-disease-analysis-and-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the dataset and separate the target variable ('y') from the predictor variable ('X')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "\n",
       "   ca  thal  \n",
       "0   2     3  \n",
       "1   0     3  \n",
       "2   0     3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/heart.csv\"))\n",
    "\n",
    "# Separate predictors and target\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(X.shape)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_test = (pd.read_csv(\"outputs/datasets/cleaned/TargetTestSet.csv\"))\n",
    "y_train = (pd.read_csv(\"outputs/datasets/cleaned/TargetTrainSet.csv\"))\n",
    "X_test = (pd.read_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\"))\n",
    "X_train = (pd.read_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error was found , for the y_train and y_test being a 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       1\n",
       "1       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used ravel to make both of them a 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.values.ravel()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.values.ravel()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Pipeline with Data Cleaning and Feature Engineering already discussed in previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;YeoJohnsonTransformer&#x27;,\n",
       "                 YeoJohnsonTransformer(variables=[&#x27;age&#x27;, &#x27;cp&#x27;, &#x27;trestbps&#x27;,\n",
       "                                                  &#x27;chol&#x27;, &#x27;restecg&#x27;, &#x27;thalach&#x27;,\n",
       "                                                  &#x27;oldpeak&#x27;, &#x27;slope&#x27;, &#x27;ca&#x27;,\n",
       "                                                  &#x27;thal&#x27;]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;YeoJohnsonTransformer&#x27;,\n",
       "                 YeoJohnsonTransformer(variables=[&#x27;age&#x27;, &#x27;cp&#x27;, &#x27;trestbps&#x27;,\n",
       "                                                  &#x27;chol&#x27;, &#x27;restecg&#x27;, &#x27;thalach&#x27;,\n",
       "                                                  &#x27;oldpeak&#x27;, &#x27;slope&#x27;, &#x27;ca&#x27;,\n",
       "                                                  &#x27;thal&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">YeoJohnsonTransformer</label><div class=\"sk-toggleable__content\"><pre>YeoJohnsonTransformer(variables=[&#x27;age&#x27;, &#x27;cp&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;restecg&#x27;,\n",
       "                                 &#x27;thalach&#x27;, &#x27;oldpeak&#x27;, &#x27;slope&#x27;, &#x27;ca&#x27;, &#x27;thal&#x27;])</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('YeoJohnsonTransformer',\n",
       "                 YeoJohnsonTransformer(variables=['age', 'cp', 'trestbps',\n",
       "                                                  'chol', 'restecg', 'thalach',\n",
       "                                                  'oldpeak', 'slope', 'ca',\n",
       "                                                  'thal']))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "\n",
    "def pipeline_transformation():\n",
    "  pipeline_base = Pipeline([\n",
    "         (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['age','cp','trestbps','chol','restecg','thalach','oldpeak','slope','ca','thal']) )\n",
    "  ])\n",
    "\n",
    "  return pipeline_base\n",
    "\n",
    "pipeline_transformation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Feat Scaling\n",
    "from sklearn.feature_selection import SelectFromModel # Feature Selection\n",
    "\n",
    "def pipeline_clf(model):\n",
    "  pipeline_base = Pipeline([\n",
    "       (\"scaler\",StandardScaler() ),\n",
    "        (\"feature_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "  ])\n",
    "\n",
    "  return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is a custom class, used with permission from the Code Institute 'Churnometer' walkthrough project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = pipeline_clf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps will identify the best Model and Hyperparameters to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models_quick_search = {\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"XGBClassifier\":{},\n",
    "    \"DecisionTreeClassifier\":{},\n",
    "    \"RandomForestClassifier\":{},\n",
    "    \"GradientBoostingClassifier\":{},\n",
    "    \"ExtraTreesClassifier\":{},\n",
    "    \"AdaBoostClassifier\":{},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostClassifier \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "quick_search.fit(X_train, y_train,\n",
    "                 scoring = make_scorer(recall_score, labels=[0], average=None),\n",
    "                 n_jobs=-1,\n",
    "                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751587</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.074566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.737037</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.043618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.735979</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.090492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.06892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.700794</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.048322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.098566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator min_score mean_score max_score std_score\n",
       "0               XGBClassifier  0.666667   0.751587  0.857143  0.074566\n",
       "3  GradientBoostingClassifier  0.666667   0.737037  0.785714  0.043618\n",
       "4        ExtraTreesClassifier   0.62963   0.735979  0.892857  0.090492\n",
       "2      RandomForestClassifier   0.62963   0.722222  0.821429   0.06892\n",
       "1      DecisionTreeClassifier   0.62963   0.700794  0.777778  0.048322\n",
       "5          AdaBoostClassifier  0.555556   0.677778  0.857143  0.098566"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the grid result the three best model with a mean score of maximum 0.75 were:\n",
    "\n",
    "- XGBClassifier with 0.75 mean score\n",
    "- GradientBoostingClassifier with 0.73 mean score\n",
    "- ExtraTreesClassifier with 0.73 mean score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main issue with the model and performance , was a performance and accuracy of 100 %. To resolve this issue developer tried different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First approach:\n",
    "- Developer checked that split of train and test set for issues, thinking the issue was data leakage.\n",
    "- Reload all sets , and tried to check for leaked data.\n",
    "- Issue was not solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second approach:\n",
    "- Developer found out that the main issue was the duplicates in the train and test set that were bringing the accuracy to 100 %.\n",
    "- Developer tried to eliminate just the duplicates from the test set.\n",
    "- Issue was not solved ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third approach:\n",
    "- To eliminate the duplicates from the test set and the train set.\n",
    "- The performance gave a result of 0.85 % resolving the 100 % issue.\n",
    "- Issue was solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensive search on the most suitable model to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "models_search = {\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "\n",
    "params_search = {\n",
    "    \"XGBClassifier\": {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 4, 5],\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 4, 5],\n",
    "    },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        \"model__n_estimators\": [20],\n",
    "        \"model__max_depth\": [5],\n",
    "        \"model__min_samples_split\": [2],\n",
    "        \"model__min_samples_leaf\": [1],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "models_search = {\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "\n",
    "params_search = {\n",
    "    \"XGBClassifier\": {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 4, 5],\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        'model__n_estimators': [50, 100, 200, 300, 400],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "        'model__max_depth': [3, 4, 5, 6, 7],\n",
    "        'model__min_samples_split': [2, 3, 4, 5, 6],\n",
    "        'model__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "        'model__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        \"model__n_estimators\": [20],\n",
    "        \"model__max_depth\": [5],\n",
    "        \"model__min_samples_split\": [2],\n",
    "        \"model__min_samples_leaf\": [1],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBClassifier \n",
      "\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingClassifier \n",
      "\n",
      "Fitting 5 folds for each of 15625 candidates, totalling 78125 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, make_scorer\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=1),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary above we note that the 2 best models are XGBClassifier and ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier has been chosen as the best model.\n",
    "Choosing the best Hyperparameter as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the complete pipeline of the best model, including all preprocessing steps and the estimator itself, with the parameters set to their optimal values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classification_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_classification_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature inportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': X_train.columns[best_classification_pipeline['feature_selection'].get_support()],\n",
    "    'Importance': best_classification_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important features:\n",
    "\n",
    "- **cp** 0,75\n",
    "- **ca** and **thal** 0.20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=best_classification_pipeline,\n",
    "                label_map= ['No disease', 'Disease'] \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set: \n",
    "\n",
    "- The report for the no disease is higher with a precision of the 0.87 and recall of 0.76.\n",
    "- The report for the disease lower with a precision of the 0.82 and recall of 0.91.\n",
    "- Mean accuracy of 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set: \n",
    "\n",
    "- The Report for the no disease is higher with a precision of the 0.90 and recall of 0.76.\n",
    "- The report for the disease lower with a precision of the 0.82 and recall of 0.93.\n",
    "- Mean accuracy of 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create a new pipeline, using the best model and the best hyperparameters from the research above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def xgbclassifier_pipeline():\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['age','cp','trestbps','chol','restecg','thalach','oldpeak','slope','ca','thal'])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(estimator=model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "# Create the XGBoost pipeline with hyperparameters\n",
    "xgb_pipeline = xgbclassifier_pipeline()\n",
    "xgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "confusion_matrix(y_true=xgb_pipeline.predict(X_test), y_pred=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=xgb_pipeline.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the classification report using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline.predict(X_test), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap and the report we can see that:\n",
    "\n",
    "- the precision for class 0 is 0.92\n",
    "- the precision for class 1 is 0.82\n",
    "- the recall for class 0 is 0.75\n",
    "- the recall for class 1 is 0.94\n",
    "- accuracy of 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Refit pipeline with best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite ml pipeline using best models, hyperparameters and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train.filter(best_features)\n",
    "X_test_filtered = X_test.filter(best_features)\n",
    "\n",
    "print(X_train_filtered.shape, y_train.shape, X_test_filtered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaxamine performance of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def xgbclassifier_pipeline_1():\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['ca', 'cp', 'thal'])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(estimator=model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "# Create the XGBoost pipeline with hyperparameters\n",
    "xgb_pipeline_1 = xgbclassifier_pipeline_1()\n",
    "xgb_pipeline_1.fit(X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report_1(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train_filtered, y_train, X_test_filtered, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train_filtered, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test_filtered, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=xgb_pipeline_1.predict(X_test_filtered), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline_1.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 1')\n",
    "plt.show()\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "# Define the filename for this plot\n",
    "plot_filename_classification_report_1 = f'{file_path}/classification_report_1.png'\n",
    "\n",
    "# Set up the saving parameters (ensure no actual saving happens in this section)\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training model just on best features the performance of both sets dropped of 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer decided to not use these combination of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to refit pipeline with features Selection from previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correlation_features = [ 'cp', 'chol', 'thalach','exang', 'oldpeak', 'ca']\n",
    "best_correlation_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter again the train and test set with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered_2 = X_train.filter(best_correlation_features)\n",
    "X_test_filtered_2 = X_test.filter(best_correlation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_filtered_2.shape, y_train.shape, X_test_filtered_2.shape, y_test.shape)\n",
    "X_train_filtered_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaxamine performance of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def xgbclassifier_pipeline_2():\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**hyperparameters)\n",
    "\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"YeoJohnsonTransformer\", YeoJohnsonTransformer(variables=['cp', 'chol', 'thalach','exang', 'oldpeak', 'ca'])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(estimator=model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "# Create the XGBoost pipeline with hyperparameters\n",
    "xgb_pipeline_2 = xgbclassifier_pipeline_2()\n",
    "xgb_pipeline_2.fit(X_train_filtered_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "\n",
    "    prediction = pipeline.predict(X)\n",
    "\n",
    "    print('---  Confusion Matrix  ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
    "          ))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print('---  Classification Report  ---')\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train_filtered_2, y_train, X_test_filtered_2, y_test, pipeline, label_map):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train_filtered_2, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test_filtered_2, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=xgb_pipeline_2.predict(X_test_filtered_2), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline_2.predict(X_test_filtered_2), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 2')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "version = 'v2'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "# Define the filename for this plot\n",
    "plot_filename_classification_report_2 = f'{file_path}/classification_report_2.png'\n",
    "\n",
    "# Set up the saving parameters (ensure no actual saving happens in this section)\n",
    "plt.ioff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance report:\n",
    "\n",
    "- the precision for class 0 is 0.73\n",
    "- the precision for class 1 is 0.78\n",
    "- the recall for class 0 is 0.76\n",
    "- the recall for class 1 is 0.76\n",
    "- accuracy of 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "- Again the developer found that this combination of features does not bring higher or relative equal performance to the one with all features.\n",
    "- Performance dropped from an accuracy of 0.86 to 0.76.\n",
    "- The test and train set will be saved already filtered without duplicates to be used in next notebook.\n",
    "- Pipeline will be saved to try in next notebook different combination of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and push file to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the following files:\n",
    "\n",
    "- Train set without duplicates\n",
    "- Test set without duplicates\n",
    "- Data cleaning and Feature Engineering and modeling pipeline with 3 features\n",
    "- Data cleaning and Feature Engineering and modeling pipeline with 6 features\n",
    "- First heatmap plot\n",
    "- Second heatmap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_filtered\n",
    "X_test = X_test_filtered\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save First pipeline with three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier_pipeline_1 = xgb_pipeline_1\n",
    "xgbclassifier_pipeline_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(value=xgbclassifier_pipeline_1,\n",
    "            filename=f\"{file_path}/xgbclassifier_pipeline_1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save plot showing feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.savefig(f'{file_path}/best_3_features_importance.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save heatmap report on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline_1.predict(X_test_filtered), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 1')\n",
    "\n",
    "# Save the plot to the specified filename\n",
    "plt.savefig(plot_filename_classification_report_1, bbox_inches='tight')\n",
    "\n",
    "# Display the saved plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving second version pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "version = 'v2'\n",
    "file_path = f'outputs/ml_pipeline/predict_heart_disease/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_filtered_2\n",
    "X_test = X_test_filtered_2\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save second pipeline with correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier_pipeline_2 = xgb_pipeline_2\n",
    "xgbclassifier_pipeline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(value=xgbclassifier_pipeline_2,\n",
    "            filename=f\"{file_path}/xgbclassifier_pipeline_2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save heatmap report on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_pred=xgb_pipeline_2.predict(X_test_filtered_2), y_true=y_test, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot the classification report using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_report.iloc[:-1, :3], annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Classification Report 2')\n",
    "\n",
    "# Save the plot to the specified filename\n",
    "plt.savefig(plot_filename_classification_report_2, bbox_inches='tight')\n",
    "\n",
    "# Display the saved plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
